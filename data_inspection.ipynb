{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.mixture import GMM\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', header=None)\n",
    "train.columns = range(1, 41)\n",
    "label = pd.read_csv('trainLabels.csv', header=None)\n",
    "label.columns = ['label']\n",
    "test = pd.read_csv('test.csv', header=None)\n",
    "test.columns = range(1, 41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_label = train.join(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot2feature(df, f1, f2, label='label'):\n",
    "    ## This method is used to plot a scatter plot\n",
    "    ## Input\n",
    "    ## df: a data frame with all features and a column for binary labels\n",
    "    ## f1: label for the first feature\n",
    "    ## f2: label for the second feature\n",
    "    ## label: label for the binary label, default is 'label\"\n",
    "    for (target, c) in zip((0, 1), ('r', 'g')):\n",
    "        plt.scatter(df[df[label]==target][f1], df[df[label]==target][f2], c = c, label=str(target), alpha = 0.5)\n",
    "    plt.legend()\n",
    "    plt.xlabel(f1)\n",
    "    plt.ylabel(f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEPCAYAAABP1MOPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQCKRSPo5/x+cwZ0my5/0AgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xab649c8c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot2feature(train_label, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = cross_validation.train_test_split(train_label[range(1, 41, 1)], \n",
    "                                                                     train_label['label'], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49866666666666665"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.544"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM without reducing dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svm_clf = svm.SVC(kernel='linear', C=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.support_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83599999999999997"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_svm(df, features, label = 'label', kernel = 'rbf'):\n",
    "    ### method to perform svm and report accuracy\n",
    "    x_train, x_test, y_train, y_test = cross_validation.train_test_split(df[features], df[label], random_state = 0)\n",
    "    # svm_clf = svm.SVC(gamma=0.01)\n",
    "    svm_clf = svm.SVC(kernel = kernel) \n",
    "    svm_clf.fit(x_train, y_train)\n",
    "    return svm_clf.score(x_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90400000000000003"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_svm(train_label, range(1, 41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-0dea02a8b34e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfit_svm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'tr' is not defined"
     ]
    }
   ],
   "source": [
    "fit_svm(tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the distribution of data and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.025596</td>\n",
       "      <td>-0.024526</td>\n",
       "      <td>-0.024088</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>1.092329</td>\n",
       "      <td>-0.006250</td>\n",
       "      <td>0.497342</td>\n",
       "      <td>-0.037883</td>\n",
       "      <td>0.026391</td>\n",
       "      <td>-0.003597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022951</td>\n",
       "      <td>-0.542491</td>\n",
       "      <td>-0.011608</td>\n",
       "      <td>-0.483507</td>\n",
       "      <td>0.033371</td>\n",
       "      <td>0.567185</td>\n",
       "      <td>0.006849</td>\n",
       "      <td>-0.892659</td>\n",
       "      <td>0.609451</td>\n",
       "      <td>0.51000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.008282</td>\n",
       "      <td>1.016298</td>\n",
       "      <td>0.979109</td>\n",
       "      <td>0.970575</td>\n",
       "      <td>4.538834</td>\n",
       "      <td>0.989128</td>\n",
       "      <td>2.118819</td>\n",
       "      <td>2.232256</td>\n",
       "      <td>1.001064</td>\n",
       "      <td>1.013520</td>\n",
       "      <td>...</td>\n",
       "      <td>1.001375</td>\n",
       "      <td>2.239939</td>\n",
       "      <td>1.022456</td>\n",
       "      <td>2.121281</td>\n",
       "      <td>1.007044</td>\n",
       "      <td>2.227876</td>\n",
       "      <td>0.997635</td>\n",
       "      <td>2.022022</td>\n",
       "      <td>2.045439</td>\n",
       "      <td>0.50015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.365711</td>\n",
       "      <td>-3.492086</td>\n",
       "      <td>-2.695602</td>\n",
       "      <td>-3.460471</td>\n",
       "      <td>-16.421901</td>\n",
       "      <td>-3.041250</td>\n",
       "      <td>-7.224761</td>\n",
       "      <td>-6.509084</td>\n",
       "      <td>-3.145588</td>\n",
       "      <td>-2.749812</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.971125</td>\n",
       "      <td>-7.840890</td>\n",
       "      <td>-2.999564</td>\n",
       "      <td>-7.124105</td>\n",
       "      <td>-2.952358</td>\n",
       "      <td>-5.452254</td>\n",
       "      <td>-3.473913</td>\n",
       "      <td>-8.051722</td>\n",
       "      <td>-7.799086</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.669010</td>\n",
       "      <td>-0.693937</td>\n",
       "      <td>-0.698830</td>\n",
       "      <td>-0.617557</td>\n",
       "      <td>-1.801997</td>\n",
       "      <td>-0.732265</td>\n",
       "      <td>-0.838619</td>\n",
       "      <td>-1.604037</td>\n",
       "      <td>-0.677562</td>\n",
       "      <td>-0.682220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.696032</td>\n",
       "      <td>-2.121943</td>\n",
       "      <td>-0.664550</td>\n",
       "      <td>-1.879247</td>\n",
       "      <td>-0.642861</td>\n",
       "      <td>-1.059786</td>\n",
       "      <td>-0.691162</td>\n",
       "      <td>-2.220126</td>\n",
       "      <td>-0.565041</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.027895</td>\n",
       "      <td>-0.033194</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.862818</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>0.582321</td>\n",
       "      <td>0.018809</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>-0.036110</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049778</td>\n",
       "      <td>-0.568262</td>\n",
       "      <td>-0.028097</td>\n",
       "      <td>-0.493575</td>\n",
       "      <td>0.037732</td>\n",
       "      <td>0.455474</td>\n",
       "      <td>0.038284</td>\n",
       "      <td>-0.855470</td>\n",
       "      <td>0.779944</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.762520</td>\n",
       "      <td>0.682753</td>\n",
       "      <td>0.661434</td>\n",
       "      <td>0.640743</td>\n",
       "      <td>3.843172</td>\n",
       "      <td>0.671456</td>\n",
       "      <td>1.913664</td>\n",
       "      <td>1.438304</td>\n",
       "      <td>0.741310</td>\n",
       "      <td>0.665364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699917</td>\n",
       "      <td>0.939348</td>\n",
       "      <td>0.651374</td>\n",
       "      <td>1.005795</td>\n",
       "      <td>0.691800</td>\n",
       "      <td>2.122157</td>\n",
       "      <td>0.693535</td>\n",
       "      <td>0.388698</td>\n",
       "      <td>1.992193</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.326246</td>\n",
       "      <td>3.583870</td>\n",
       "      <td>2.546507</td>\n",
       "      <td>3.088738</td>\n",
       "      <td>17.565345</td>\n",
       "      <td>3.102997</td>\n",
       "      <td>7.592666</td>\n",
       "      <td>7.130097</td>\n",
       "      <td>3.145258</td>\n",
       "      <td>3.919426</td>\n",
       "      <td>...</td>\n",
       "      <td>3.688047</td>\n",
       "      <td>7.160379</td>\n",
       "      <td>3.353631</td>\n",
       "      <td>6.005818</td>\n",
       "      <td>3.420561</td>\n",
       "      <td>6.603499</td>\n",
       "      <td>3.492548</td>\n",
       "      <td>5.774120</td>\n",
       "      <td>6.803984</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 1            2            3            4            5  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.025596    -0.024526    -0.024088    -0.002271     1.092329   \n",
       "std       1.008282     1.016298     0.979109     0.970575     4.538834   \n",
       "min      -3.365711    -3.492086    -2.695602    -3.460471   -16.421901   \n",
       "25%      -0.669010    -0.693937    -0.698830    -0.617557    -1.801997   \n",
       "50%       0.027895    -0.033194     0.008145     0.002327     0.862818   \n",
       "75%       0.762520     0.682753     0.661434     0.640743     3.843172   \n",
       "max       3.326246     3.583870     2.546507     3.088738    17.565345   \n",
       "\n",
       "                 6            7            8            9           10  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     -0.006250     0.497342    -0.037883     0.026391    -0.003597   \n",
       "std       0.989128     2.118819     2.232256     1.001064     1.013520   \n",
       "min      -3.041250    -7.224761    -6.509084    -3.145588    -2.749812   \n",
       "25%      -0.732265    -0.838619    -1.604037    -0.677562    -0.682220   \n",
       "50%       0.027041     0.582321     0.018809     0.022092    -0.036110   \n",
       "75%       0.671456     1.913664     1.438304     0.741310     0.665364   \n",
       "max       3.102997     7.592666     7.130097     3.145258     3.919426   \n",
       "\n",
       "          ...               32           33           34           35  \\\n",
       "count     ...      1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      ...         0.022951    -0.542491    -0.011608    -0.483507   \n",
       "std       ...         1.001375     2.239939     1.022456     2.121281   \n",
       "min       ...        -2.971125    -7.840890    -2.999564    -7.124105   \n",
       "25%       ...        -0.696032    -2.121943    -0.664550    -1.879247   \n",
       "50%       ...         0.049778    -0.568262    -0.028097    -0.493575   \n",
       "75%       ...         0.699917     0.939348     0.651374     1.005795   \n",
       "max       ...         3.688047     7.160379     3.353631     6.005818   \n",
       "\n",
       "                36           37           38           39           40  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean      0.033371     0.567185     0.006849    -0.892659     0.609451   \n",
       "std       1.007044     2.227876     0.997635     2.022022     2.045439   \n",
       "min      -2.952358    -5.452254    -3.473913    -8.051722    -7.799086   \n",
       "25%      -0.642861    -1.059786    -0.691162    -2.220126    -0.565041   \n",
       "50%       0.037732     0.455474     0.038284    -0.855470     0.779944   \n",
       "75%       0.691800     2.122157     0.693535     0.388698     1.992193   \n",
       "max       3.420561     6.603499     3.492548     5.774120     6.803984   \n",
       "\n",
       "            label  \n",
       "count  1000.00000  \n",
       "mean      0.51000  \n",
       "std       0.50015  \n",
       "min       0.00000  \n",
       "25%       0.00000  \n",
       "50%       1.00000  \n",
       "75%       1.00000  \n",
       "max       1.00000  \n",
       "\n",
       "[8 rows x 41 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_label_scaled = pd.DataFrame(preprocessing.scale(train_label[range(1, 41)]), columns=range(1,41)).join(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86399999999999999"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_svm(train_label_scaled, range(1,41))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the effect of dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xa83af14c>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkQT5/++Mm5TDZXTtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa842fc8c>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot([fit_svm(train_label, range(1, i+1)) for i in range(1, 41)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'             precision    recall  f1-score   support\\n\\n          0       0.83      0.81      0.82       114\\n          1       0.84      0.86      0.85       136\\n\\navg / total       0.84      0.84      0.84       250\\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test, svm_clf.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## gridsearchcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "def gridsearch_svc(parameters, df, features, label='label', scores = ['accuracy']):\n",
    "    ### perform gridsearchcv for svc model\n",
    "    ### df: dataframe with training dataset\n",
    "    ### features: list of feature labels (x's)\n",
    "    ### label: column name for label (y)\n",
    "    ### parameters: parameter space for gridsearchcv\n",
    "    ### scores: list of scoring functions\n",
    "    \n",
    "    # get train and test data\n",
    "    x_train, x_test, y_train, y_test = cross_validation.train_test_split(df[features],\n",
    "                                                                     df[label], random_state = 0, test_size = 0.1)\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(svm.SVC(), parameters, cv=3,\n",
    "                           scoring=score)\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        for params, mean_score, scores in clf.grid_scores_:\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean_score, scores.std() * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(x_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "    return clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tuned_parameters = [{'C': [10, 100, 1000], 'gamma': [0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},   \n",
    "#                    {'C': [1, 10, 100, 1000], 'kernel': ['linear']}]\n",
    "tuned_parameters =  {'C': [1, 10, 100], 'kernel': ['linear']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.517 (+/-0.014) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.1}\n",
      "0.877 (+/-0.052) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.05}\n",
      "0.894 (+/-0.037) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.01}\n",
      "0.886 (+/-0.038) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.005}\n",
      "0.838 (+/-0.043) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.548 (+/-0.002) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.1}\n",
      "0.881 (+/-0.049) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.05}\n",
      "0.917 (+/-0.020) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "0.900 (+/-0.016) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.005}\n",
      "0.859 (+/-0.057) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.548 (+/-0.002) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.1}\n",
      "0.881 (+/-0.049) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.05}\n",
      "0.917 (+/-0.020) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.01}\n",
      "0.893 (+/-0.025) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.005}\n",
      "0.884 (+/-0.039) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91        45\n",
      "          1       0.96      0.87      0.91        55\n",
      "\n",
      "avg / total       0.92      0.91      0.91       100\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "clf = gridsearch_svc(tuned_parameters, train_label, range(1, 41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(474, 40)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.support_vectors_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 0.05}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.851 (+/-0.038) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.1}\n",
      "0.853 (+/-0.041) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.05}\n",
      "0.829 (+/-0.057) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.01}\n",
      "0.823 (+/-0.049) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.005}\n",
      "0.817 (+/-0.053) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.853 (+/-0.038) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.1}\n",
      "0.866 (+/-0.058) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.05}\n",
      "0.866 (+/-0.033) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "0.842 (+/-0.049) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.005}\n",
      "0.826 (+/-0.054) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.853 (+/-0.038) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.1}\n",
      "0.866 (+/-0.058) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.05}\n",
      "0.858 (+/-0.024) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.01}\n",
      "0.852 (+/-0.031) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.005}\n",
      "0.836 (+/-0.043) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.91      0.87        45\n",
      "          1       0.92      0.85      0.89        55\n",
      "\n",
      "avg / total       0.88      0.88      0.88       100\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "clf = gridsearch_svc(tuned_parameters, train_label_scaled, range(1, 41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(438,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.support_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Summary1\n",
    "* This data set is pretty balanced.\n",
    "* Straight SVM works and better than scaled (why??)\n",
    "* Linear kernel is slower than rbf\n",
    "* rbf kernel performs better than linear kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scaled = pd.DataFrame(preprocessing.scale(train_label[range(1, 41)]), columns=range(1,41))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 0.05}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.842 (+/-0.046) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.1}\n",
      "0.853 (+/-0.043) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.05}\n",
      "0.828 (+/-0.054) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.01}\n",
      "0.816 (+/-0.045) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.005}\n",
      "0.809 (+/-0.035) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.843 (+/-0.032) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.1}\n",
      "0.847 (+/-0.044) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.05}\n",
      "0.846 (+/-0.036) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "0.847 (+/-0.032) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.005}\n",
      "0.807 (+/-0.042) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.843 (+/-0.032) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.1}\n",
      "0.847 (+/-0.044) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.05}\n",
      "0.817 (+/-0.004) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.01}\n",
      "0.816 (+/-0.017) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.005}\n",
      "0.832 (+/-0.055) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.84      0.83        45\n",
      "          1       0.87      0.84      0.85        55\n",
      "\n",
      "avg / total       0.84      0.84      0.84       100\n",
      "\n",
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.05, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scratch\n",
    "# perform pca on scaled data and do svm\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.9)\n",
    "scaled_pca = pd.DataFrame(pca.fit_transform(scaled))\n",
    "n_pca = scaled_pca.shape[1]\n",
    "scaled_pca.columns = range(1, n_pca + 1)\n",
    "scaled_pca = scaled_pca.join(label)\n",
    "tuned_parameters = {'C': [1, 10, 100], 'gamma': [0.1,0.05, 0.01, 0.005, 0.001], 'kernel': ['rbf']}\n",
    "gridsearch_svc(tuned_parameters, scaled_pca, range(1, n_pca+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 0.01}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.799 (+/-0.112) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.1}\n",
      "0.893 (+/-0.031) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.05}\n",
      "0.909 (+/-0.033) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.01}\n",
      "0.888 (+/-0.038) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.005}\n",
      "0.831 (+/-0.040) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.808 (+/-0.099) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.1}\n",
      "0.891 (+/-0.031) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.05}\n",
      "0.908 (+/-0.023) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "0.904 (+/-0.011) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.005}\n",
      "0.871 (+/-0.040) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.808 (+/-0.099) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.1}\n",
      "0.891 (+/-0.031) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.05}\n",
      "0.909 (+/-0.022) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.01}\n",
      "0.889 (+/-0.007) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.005}\n",
      "0.894 (+/-0.030) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.91      0.89        45\n",
      "          1       0.92      0.89      0.91        55\n",
      "\n",
      "avg / total       0.90      0.90      0.90       100\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# scratch\n",
    "# perform pca on raw data and do svm\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=0.9)\n",
    "raw_pca = pd.DataFrame(pca.fit_transform(train))\n",
    "n_pca = raw_pca.shape[1]\n",
    "raw_pca.columns = range(1, n_pca + 1)\n",
    "raw_pca = raw_pca.join(label)\n",
    "tuned_parameters = {'C': [1, 10, 100], 'gamma': [0.1,0.05, 0.01, 0.005, 0.001], 'kernel': ['rbf']}\n",
    "clf = gridsearch_svc(tuned_parameters, raw_pca, range(1, n_pca+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pca_gridsearch(pca, tuned_parameters, df, features, label='label', scores = ['accuracy']):\n",
    "    ### method to perform gridsearch_svc after pca\n",
    "    # input:\n",
    "    #      pca: a pca object\n",
    "    #      the rest is requred by gridseach_svc\n",
    "    df_pca = pd.DataFrame(pca.fit_transform(df[features]))\n",
    "    n_pca = df_pca.shape[1] # number of features after pca\n",
    "    df_pca.columns = range(1, n_pca + 1)\n",
    "    df_pca = df_pca.join(df[label])\n",
    "    return gridsearch_svc(tuned_parameters, df_pca, range(1, n_pca+1), label, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 1, 'gamma': 0.01}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.799 (+/-0.112) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.1}\n",
      "0.893 (+/-0.031) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.05}\n",
      "0.909 (+/-0.033) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.01}\n",
      "0.888 (+/-0.038) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.005}\n",
      "0.831 (+/-0.040) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.808 (+/-0.099) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.1}\n",
      "0.891 (+/-0.031) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.05}\n",
      "0.908 (+/-0.023) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "0.904 (+/-0.011) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.005}\n",
      "0.871 (+/-0.040) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.808 (+/-0.099) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.1}\n",
      "0.891 (+/-0.031) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.05}\n",
      "0.909 (+/-0.022) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.01}\n",
      "0.889 (+/-0.007) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.005}\n",
      "0.894 (+/-0.030) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.91      0.89        45\n",
      "          1       0.92      0.89      0.91        55\n",
      "\n",
      "avg / total       0.90      0.90      0.90       100\n",
      "\n",
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_gridsearch(pca, tuned_parameters, train_label, range(1, 41))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary2\n",
    "* PCA workflow.\n",
    "* Raw data still performs better.\n",
    "* Reducing dimension doesn't improve the accuracy. If retaining 0.9999 variance, the result is almost the same as not doing PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## a class to handle the parameters of gridsearchcv_svm\n",
    "class gridsearch:\n",
    "    def __init__(self, dataframe):\n",
    "        self.tuned_parameters = None\n",
    "        self.features = None\n",
    "        self.df = dataframe\n",
    "        self.label = 'label'\n",
    "        self.scores = ['accuracy']\n",
    "        self.n_components = 0.999\n",
    "        self.best_estimator_ = None\n",
    "    \n",
    "    # method to perform fitting\n",
    "    def fit(self):\n",
    "        ### perform gridsearchcv for svc model\n",
    "        ### df: dataframe with training dataset\n",
    "       \n",
    "        # get train and test data\n",
    "        x_train, x_test, y_train, y_test = cross_validation.train_test_split(self.df[self.features],\n",
    "                                                                         self.df[self.label], random_state = 0, test_size = 0.1)\n",
    "        for score in self.scores:\n",
    "            print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "            print()\n",
    "\n",
    "            clf = GridSearchCV(svm.SVC(), self.tuned_parameters, cv=3,\n",
    "                               scoring=score)\n",
    "            clf.fit(x_train, y_train)\n",
    "\n",
    "            print(\"Best parameters set found on development set:\")\n",
    "            print\n",
    "            print(clf.best_params_)\n",
    "            print()\n",
    "            print(\"Grid scores on development set:\")\n",
    "            print()\n",
    "            for params, mean_score, scores in clf.grid_scores_:\n",
    "                print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                      % (mean_score, scores.std() * 2, params))\n",
    "            print()\n",
    "\n",
    "            print(\"Detailed classification report:\")\n",
    "            print()\n",
    "            print(\"The model is trained on the full development set.\")\n",
    "            print(\"The scores are computed on the full evaluation set.\")\n",
    "            print()\n",
    "            y_true, y_pred = y_test, clf.predict(x_test)\n",
    "            print(classification_report(y_true, y_pred))\n",
    "            print()\n",
    "        self.best_estimator_ = clf.best_estimator_\n",
    "    \n",
    "    # method to perform PCA transform in place, also update the features\n",
    "    def pca_inplace(self):\n",
    "        pca = PCA(self.n_components)\n",
    "        df_pca = pd.DataFrame(pca.fit_transform(self.df[self.features]))\n",
    "        n_pca = df_pca.shape[1] # number of features after pca\n",
    "        df_pca.columns = range(1, n_pca + 1)\n",
    "        self.df = df_pca.join(self.df[self.label])\n",
    "        self.features = range(1, n_pca + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 0.05}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.851 (+/-0.038) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.1}\n",
      "0.853 (+/-0.041) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.05}\n",
      "0.829 (+/-0.057) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.01}\n",
      "0.823 (+/-0.049) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.005}\n",
      "0.817 (+/-0.053) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.853 (+/-0.038) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.1}\n",
      "0.866 (+/-0.058) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.05}\n",
      "0.866 (+/-0.033) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "0.842 (+/-0.049) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.005}\n",
      "0.826 (+/-0.054) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.853 (+/-0.038) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.1}\n",
      "0.866 (+/-0.058) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.05}\n",
      "0.858 (+/-0.024) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.01}\n",
      "0.852 (+/-0.031) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.005}\n",
      "0.836 (+/-0.043) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.91      0.87        45\n",
      "          1       0.92      0.85      0.89        55\n",
      "\n",
      "avg / total       0.88      0.88      0.88       100\n",
      "\n",
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.05, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use gridsearch class to perform fitting\n",
    "gd = gridsearch(train_label_scaled)\n",
    "gd.tuned_parameters = tuned_parameters = {'C': [1, 10, 100], 'gamma': [0.1,0.05, 0.01, 0.005, 0.001], 'kernel': ['rbf']}\n",
    "gd.features = range(1, 41)\n",
    "gd.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 0.005}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.876 (+/-0.059) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.1}\n",
      "0.910 (+/-0.016) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.05}\n",
      "0.914 (+/-0.041) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.01}\n",
      "0.890 (+/-0.043) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.005}\n",
      "0.833 (+/-0.032) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.879 (+/-0.052) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.1}\n",
      "0.916 (+/-0.011) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.05}\n",
      "0.914 (+/-0.006) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "0.918 (+/-0.011) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.005}\n",
      "0.871 (+/-0.053) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.879 (+/-0.052) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.1}\n",
      "0.916 (+/-0.011) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.05}\n",
      "0.908 (+/-0.009) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.01}\n",
      "0.898 (+/-0.016) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.005}\n",
      "0.913 (+/-0.051) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.98      0.93        45\n",
      "          1       0.98      0.89      0.93        55\n",
      "\n",
      "avg / total       0.94      0.93      0.93       100\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# combine gridsearch class and pca\n",
    "gd = gridsearch(train_label)\n",
    "gd.features = range(1, 41)\n",
    "gd.n_components = 12\n",
    "gd.pca_inplace()\n",
    "gd.tuned_parameters = tuned_parameters = {'C': [1, 10, 100], 'gamma': [0.1,0.05, 0.01, 0.005, 0.001], \n",
    "                                          'kernel': ['rbf']}\n",
    "gd.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.506 (+/-0.002) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1}\n",
      "0.506 (+/-0.002) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.1}\n",
      "0.832 (+/-0.026) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.01}\n",
      "0.794 (+/-0.037) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.001}\n",
      "0.506 (+/-0.002) for {'kernel': 'rbf', 'C': 1, 'gamma': 1}\n",
      "0.517 (+/-0.014) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.1}\n",
      "0.894 (+/-0.037) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.01}\n",
      "0.838 (+/-0.043) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.506 (+/-0.002) for {'kernel': 'rbf', 'C': 10, 'gamma': 1}\n",
      "0.548 (+/-0.002) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.1}\n",
      "0.917 (+/-0.020) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "0.859 (+/-0.057) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91        45\n",
      "          1       0.96      0.87      0.91        55\n",
      "\n",
      "avg / total       0.92      0.91      0.91       100\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# Use raw data\n",
    "gd = gridsearch(train_label)\n",
    "gd.tuned_parameters = tuned_parameters = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01,  0.001], 'kernel': ['rbf']}\n",
    "gd.features = range(1, 41)\n",
    "gd.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction and saving\n",
    "def test_save(estimator, test):\n",
    "    num = test.shape[0]\n",
    "    test_label = pd.DataFrame({\"Id\": range(1,num+1), \"Solution\": estimator.predict(test)}, index=None)\n",
    "    test_label.to_csv('./test_label-'+str(datetime.date.today())+'.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_save(gd.best_estimator_, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.517 (+/-0.014) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.1}\n",
      "0.877 (+/-0.052) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.05}\n",
      "0.894 (+/-0.037) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.01}\n",
      "0.886 (+/-0.038) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.005}\n",
      "0.838 (+/-0.043) for {'kernel': 'rbf', 'C': 1, 'gamma': 0.001}\n",
      "0.548 (+/-0.002) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.1}\n",
      "0.881 (+/-0.049) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.05}\n",
      "0.917 (+/-0.020) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.01}\n",
      "0.900 (+/-0.016) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.005}\n",
      "0.859 (+/-0.057) for {'kernel': 'rbf', 'C': 10, 'gamma': 0.001}\n",
      "0.548 (+/-0.002) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.1}\n",
      "0.881 (+/-0.049) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.05}\n",
      "0.917 (+/-0.020) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.01}\n",
      "0.893 (+/-0.025) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.005}\n",
      "0.884 (+/-0.039) for {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.96      0.91        45\n",
      "          1       0.96      0.87      0.91        55\n",
      "\n",
      "avg / total       0.92      0.91      0.91       100\n",
      "\n",
      "()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.01, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine gridsearch class and pca\n",
    "gd.pca_inplace()\n",
    "gd.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary2\n",
    "* Made a test submission with the predictor using svm (no pca or scaling), and the accuracy is about 91%, comparable with the result from cross-validation. This is not a great score.\n",
    "* Based on this blog (http://elenacuoco.altervista.org/blog/archives/1167), random forest can reach almost 99%, but GMM is needed to transform the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "def fit_randomforest(df, features, max_features, label = 'label'):\n",
    "    ### method to perform svm and report accuracy\n",
    "    x_train, x_test, y_train, y_test = cross_validation.train_test_split(df[features], df[label], random_state = 0)\n",
    "    rf_clf = RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=5, min_samples_split=1,\n",
    "  min_samples_leaf=3, max_features=max_features,    bootstrap=False, oob_score=False, n_jobs=1, random_state=33,\n",
    "  verbose=0) \n",
    "    rf_clf.fit(x_train, y_train)\n",
    "    return rf_clf.score(x_test, y_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796\n",
      "0.812\n",
      "0.816\n",
      "0.82\n",
      "0.84\n",
      "0.836\n",
      "0.836\n",
      "0.84\n",
      "0.852\n",
      "0.848\n",
      "0.852\n",
      "0.852\n",
      "0.848\n",
      "0.848\n",
      "0.852\n",
      "0.852\n",
      "0.848\n",
      "0.848\n",
      "0.856\n",
      "0.848\n",
      "0.844\n",
      "0.84\n",
      "0.844\n",
      "0.84\n",
      "0.84\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-ffbf494c2f35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m41\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mprint\u001b[0m \u001b[0mfit_randomforest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m41\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-23cbbe4be2bc>\u001b[0m in \u001b[0;36mfit_randomforest\u001b[1;34m(df, features, max_features, label)\u001b[0m\n\u001b[0;32m      7\u001b[0m   \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mbootstrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moob_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m33\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m   verbose=0) \n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mrf_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mrf_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yu/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    288\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 290\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    798\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    656\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yu/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yu/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/yu/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    348\u001b[0m                                            max_leaf_nodes)\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n in range(1, 41):\n",
    "    print fit_randomforest(train_label, range(1, 41), n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.77147819,  0.61563317, -1.99300318, ..., -1.05017228,\n",
       "        -0.77530532, -0.38070158],\n",
       "       [-0.30945517,  1.53409344, -1.08409627, ...,  0.43182273,\n",
       "         1.18375205,  2.58760961],\n",
       "       [ 0.56251975,  0.88094879,  0.10181214, ..., -0.20523439,\n",
       "        -1.48716119,  1.02473035],\n",
       "       ..., \n",
       "       [ 1.19222208, -0.41437073,  0.06705418, ...,  0.6564375 ,\n",
       "        -0.93247282,  2.9874358 ],\n",
       "       [ 1.50622633,  0.14599688,  0.42849583, ...,  1.97195112,\n",
       "        -1.29560131, -1.15846118],\n",
       "       [ 0.17513613, -0.66114704, -2.09535416, ...,  0.10653325,\n",
       "        -3.21961479, -0.72449445]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_all = x_train.append(x_test)\n",
    "x_all.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform GMM on full test data to get clusters\n",
    "# http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_selection.html#example-mixture-plot-gmm-selection-py\n",
    "#x_all = x_train.append(x_test)\n",
    "x_all = train.append(test)\n",
    "x_all = x_all.values\n",
    "\n",
    "lowest_bic = np.infty\n",
    "bic = []\n",
    "n_components_range = range(2, 20)\n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "for cv_type in cv_types:\n",
    "    for n_components in n_components_range:\n",
    "        # Fit a mixture of Gaussians with EM\n",
    "        gmm = GMM(n_components=n_components, covariance_type=cv_type)\n",
    "        gmm.fit(x_all)\n",
    "        bic.append(gmm.aic(x_all)) # aic is used. Wiki suggests that aic is better than bic\n",
    "        if bic[-1] < lowest_bic:\n",
    "            lowest_bic = bic[-1]\n",
    "            best_gmm = gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GMM(covariance_type='full', init_params='wmc', min_covar=0.001,\n",
       "  n_components=4, n_init=1, n_iter=100, params='wmc', random_state=None,\n",
       "  thresh=None, tol=0.001, verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check best_gmm\n",
    "best_gmm\n",
    "#plt.plot(bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit with randomforest\n",
    "x_train_gmm = best_gmm.predict_proba(x_train)\n",
    "# clf=RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=5, min_samples_split=1,\n",
    "#  min_samples_leaf=3, max_features='auto',    bootstrap=False, oob_score=False, n_jobs=1, random_state=33,\n",
    "#  verbose=0)\n",
    "clf=RandomForestClassifier(n_estimators=1000, criterion='entropy', max_depth=5)\n",
    "\n",
    "clf.fit(x_train_gmm, y_train)\n",
    "clf.score(best_gmm.predict_proba(x_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_save(clf, best_gmm.predict_proba(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 0.3, 'gamma': 1}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.513 (+/-0.042) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 1}\n",
      "0.502 (+/-0.019) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "0.502 (+/-0.019) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.6}\n",
      "0.505 (+/-0.010) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.4}\n",
      "0.508 (+/-0.002) for {'kernel': 'rbf', 'C': 0.1, 'gamma': 0.1}\n",
      "0.526 (+/-0.053) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 1}\n",
      "0.526 (+/-0.053) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 0.8}\n",
      "0.526 (+/-0.053) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 0.6}\n",
      "0.526 (+/-0.053) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 0.4}\n",
      "0.505 (+/-0.010) for {'kernel': 'rbf', 'C': 0.3, 'gamma': 0.1}\n",
      "0.526 (+/-0.053) for {'kernel': 'rbf', 'C': 0.5, 'gamma': 1}\n",
      "0.526 (+/-0.053) for {'kernel': 'rbf', 'C': 0.5, 'gamma': 0.8}\n",
      "0.526 (+/-0.053) for {'kernel': 'rbf', 'C': 0.5, 'gamma': 0.6}\n",
      "0.526 (+/-0.053) for {'kernel': 'rbf', 'C': 0.5, 'gamma': 0.4}\n",
      "0.513 (+/-0.042) for {'kernel': 'rbf', 'C': 0.5, 'gamma': 0.1}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.47      0.23      0.31        30\n",
      "          1       0.62      0.82      0.70        45\n",
      "\n",
      "avg / total       0.56      0.59      0.55        75\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# Fit with svm. The result is very bad. Something is wrong.\n",
    "tuned_parameters = {'C': [0.1, 0.3, 0.5], 'gamma': [1, 0.8, 0.6, 0.4, 0.1], 'kernel': ['rbf']}\n",
    "x_train_gmm_df = pd.DataFrame(x_train_gmm)\n",
    "x_train_gmm_df = x_train_gmm_df.join(label)\n",
    "gmm_svm = gridsearch(x_train_gmm_df)\n",
    "gmm_svm.features = range(best_gmm.n_components)\n",
    "gmm_svm.tuned_parameters = tuned_parameters\n",
    "gmm_svm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435048</td>\n",
       "      <td>0.425664</td>\n",
       "      <td>0.427447</td>\n",
       "      <td>0.442661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.398971</td>\n",
       "      <td>0.443867</td>\n",
       "      <td>0.432187</td>\n",
       "      <td>0.441496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3\n",
       "label                                        \n",
       "0      0.435048  0.425664  0.427447  0.442661\n",
       "1      0.398971  0.443867  0.432187  0.441496"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_gmm_df.groupby('label').std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for accuracy\n",
      "()\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'kernel': 'rbf', 'C': 1.5999999999999999, 'gamma': 0.90000000000000002}\n",
      "()\n",
      "Grid scores on development set:\n",
      "()\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.10000000000000001}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.20000000000000001}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.30000000000000004}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.40000000000000002}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.5}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.60000000000000009}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.70000000000000007}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.80000000000000004}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 0.10000000000000001, 'gamma': 0.90000000000000002}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 0.59999999999999998, 'gamma': 0.10000000000000001}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 0.59999999999999998, 'gamma': 0.20000000000000001}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 0.59999999999999998, 'gamma': 0.30000000000000004}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 0.59999999999999998, 'gamma': 0.40000000000000002}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 0.59999999999999998, 'gamma': 0.5}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 0.59999999999999998, 'gamma': 0.60000000000000009}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 0.59999999999999998, 'gamma': 0.70000000000000007}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 0.59999999999999998, 'gamma': 0.80000000000000004}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 0.59999999999999998, 'gamma': 0.90000000000000002}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 1.0999999999999999, 'gamma': 0.10000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.0999999999999999, 'gamma': 0.20000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.0999999999999999, 'gamma': 0.30000000000000004}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.0999999999999999, 'gamma': 0.40000000000000002}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.0999999999999999, 'gamma': 0.5}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.0999999999999999, 'gamma': 0.60000000000000009}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.0999999999999999, 'gamma': 0.70000000000000007}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.0999999999999999, 'gamma': 0.80000000000000004}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.0999999999999999, 'gamma': 0.90000000000000002}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 1.5999999999999999, 'gamma': 0.10000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.5999999999999999, 'gamma': 0.20000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.5999999999999999, 'gamma': 0.30000000000000004}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.5999999999999999, 'gamma': 0.40000000000000002}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.5999999999999999, 'gamma': 0.5}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.5999999999999999, 'gamma': 0.60000000000000009}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.5999999999999999, 'gamma': 0.70000000000000007}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 1.5999999999999999, 'gamma': 0.80000000000000004}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 1.5999999999999999, 'gamma': 0.90000000000000002}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 2.1000000000000001, 'gamma': 0.10000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 2.1000000000000001, 'gamma': 0.20000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 2.1000000000000001, 'gamma': 0.30000000000000004}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 2.1000000000000001, 'gamma': 0.40000000000000002}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 2.1000000000000001, 'gamma': 0.5}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 2.1000000000000001, 'gamma': 0.60000000000000009}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 2.1000000000000001, 'gamma': 0.70000000000000007}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 2.1000000000000001, 'gamma': 0.80000000000000004}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 2.1000000000000001, 'gamma': 0.90000000000000002}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 2.5999999999999996, 'gamma': 0.10000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 2.5999999999999996, 'gamma': 0.20000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 2.5999999999999996, 'gamma': 0.30000000000000004}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 2.5999999999999996, 'gamma': 0.40000000000000002}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 2.5999999999999996, 'gamma': 0.5}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 2.5999999999999996, 'gamma': 0.60000000000000009}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 2.5999999999999996, 'gamma': 0.70000000000000007}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 2.5999999999999996, 'gamma': 0.80000000000000004}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 2.5999999999999996, 'gamma': 0.90000000000000002}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 3.0999999999999996, 'gamma': 0.10000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 3.0999999999999996, 'gamma': 0.20000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 3.0999999999999996, 'gamma': 0.30000000000000004}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 3.0999999999999996, 'gamma': 0.40000000000000002}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 3.0999999999999996, 'gamma': 0.5}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 3.0999999999999996, 'gamma': 0.60000000000000009}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 3.0999999999999996, 'gamma': 0.70000000000000007}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 3.0999999999999996, 'gamma': 0.80000000000000004}\n",
      "0.988 (+/-0.006) for {'kernel': 'rbf', 'C': 3.0999999999999996, 'gamma': 0.90000000000000002}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 3.5999999999999996, 'gamma': 0.10000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 3.5999999999999996, 'gamma': 0.20000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 3.5999999999999996, 'gamma': 0.30000000000000004}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 3.5999999999999996, 'gamma': 0.40000000000000002}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 3.5999999999999996, 'gamma': 0.5}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 3.5999999999999996, 'gamma': 0.60000000000000009}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 3.5999999999999996, 'gamma': 0.70000000000000007}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 3.5999999999999996, 'gamma': 0.80000000000000004}\n",
      "0.988 (+/-0.006) for {'kernel': 'rbf', 'C': 3.5999999999999996, 'gamma': 0.90000000000000002}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 4.0999999999999996, 'gamma': 0.10000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 4.0999999999999996, 'gamma': 0.20000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 4.0999999999999996, 'gamma': 0.30000000000000004}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 4.0999999999999996, 'gamma': 0.40000000000000002}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 4.0999999999999996, 'gamma': 0.5}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 4.0999999999999996, 'gamma': 0.60000000000000009}\n",
      "0.988 (+/-0.006) for {'kernel': 'rbf', 'C': 4.0999999999999996, 'gamma': 0.70000000000000007}\n",
      "0.988 (+/-0.006) for {'kernel': 'rbf', 'C': 4.0999999999999996, 'gamma': 0.80000000000000004}\n",
      "0.988 (+/-0.006) for {'kernel': 'rbf', 'C': 4.0999999999999996, 'gamma': 0.90000000000000002}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 4.5999999999999996, 'gamma': 0.10000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 4.5999999999999996, 'gamma': 0.20000000000000001}\n",
      "0.988 (+/-0.008) for {'kernel': 'rbf', 'C': 4.5999999999999996, 'gamma': 0.30000000000000004}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 4.5999999999999996, 'gamma': 0.40000000000000002}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 4.5999999999999996, 'gamma': 0.5}\n",
      "0.989 (+/-0.008) for {'kernel': 'rbf', 'C': 4.5999999999999996, 'gamma': 0.60000000000000009}\n",
      "0.988 (+/-0.006) for {'kernel': 'rbf', 'C': 4.5999999999999996, 'gamma': 0.70000000000000007}\n",
      "0.988 (+/-0.006) for {'kernel': 'rbf', 'C': 4.5999999999999996, 'gamma': 0.80000000000000004}\n",
      "0.987 (+/-0.005) for {'kernel': 'rbf', 'C': 4.5999999999999996, 'gamma': 0.90000000000000002}\n",
      "()\n",
      "Detailed classification report:\n",
      "()\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "()\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        45\n",
      "          1       1.00      1.00      1.00        55\n",
      "\n",
      "avg / total       1.00      1.00      1.00       100\n",
      "\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# pca + gmm + svm\n",
    "pca = PCA(n_components=12)\n",
    "raw_pca = pd.DataFrame(pca.fit_transform(train))\n",
    "n_pca = raw_pca.shape[1]\n",
    "raw_pca.columns = range(1, n_pca + 1)\n",
    "raw_pca = raw_pca.join(label)\n",
    "tuned_parameters = {'C': np.arange(0.1, 5, 0.5), 'gamma': np.arange(0.1, 1, 0.1), 'kernel': ['rbf']}\n",
    "gmm = GMM(n_components= 4, covariance_type= 'full')\n",
    "gmm.fit(raw_pca[range(1, n_pca+1)])\n",
    "x_train_gmm = gmm.predict_proba(raw_pca[range(1, n_pca+1)])\n",
    "x_train_gmm_df = pd.DataFrame(x_train_gmm)\n",
    "x_train_gmm_df = x_train_gmm_df.join(label)\n",
    "clf = gridsearch_svc(tuned_parameters, x_train_gmm_df, range(4))\n",
    "test_save(clf, gmm.predict_proba(pca.transform(test))) # 0.98908 final score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma=0.1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "* Using x_train + x_test (=train) to fit GMM and then perform random forest with x_train, the accuracy is 0.996 with x_test. This seems unrealistic.\n",
    "* Using train + test to fit GMM, very time consuming. Perform random forest with x_train, the accuracy is about 1 with x_test. This is probably a sign of overfitting. The score using test data is 0.99145.\n",
    "* Using x_train + x_test to perform PCA, followed by GMM and SVM. The score using test data is 0.98892"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
